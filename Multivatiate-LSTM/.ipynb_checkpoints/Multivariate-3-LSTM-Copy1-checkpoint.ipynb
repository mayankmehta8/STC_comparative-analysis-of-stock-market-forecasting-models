{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S19jleua1_GE"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XGXh32Yl3E5s"
   },
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "import datetime as dt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FNioyc6mZUAJ"
   },
   "outputs": [],
   "source": [
    "# Setting up an early stop\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=80,  verbose=1, mode='min')\n",
    "callbacks_list = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r5O0a39R9Z_Z"
   },
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "url = 'https://raw.githubusercontent.com/ninja3697/dataset/master/CSV.csv'\n",
    "#url = '../../CSV.csv'\n",
    "df = pd.read_csv(url,parse_dates = True,index_col=0)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2H5Lkte_NgWT"
   },
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "df.corr()['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1anbu_yx3bta"
   },
   "outputs": [],
   "source": [
    "print(df.describe().Volume) \n",
    "df.drop(df[df['Volume']==0].index, inplace = True) #Dropping rows with volume value 0\n",
    "df['Volume'].hist(bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = np.arange(30,55,10)\n",
    "hl = []\n",
    "for i in range(30,55,10):\n",
    "    hl.append([i,i-5])\n",
    "lr = [1e-5,1e-4,1e-3,1e-2,1e-1]\n",
    "batch_size = [16,32,64]\n",
    "num_epochs = [20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zRVEzZ1FXj_p"
   },
   "outputs": [],
   "source": [
    "#Build and train the model\n",
    "def fit_model(train,val,timesteps,hl,lr,batch,epochs):\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_val = []\n",
    "    Y_val = []\n",
    "  \n",
    "    # Loop for training data\n",
    "    for i in range(timesteps,train.shape[0]):\n",
    "        X_train.append(train[i-timesteps:i])\n",
    "        Y_train.append(train[i][0])\n",
    "    X_train,Y_train = np.array(X_train),np.array(Y_train)\n",
    "  \n",
    "    # Loop for val data\n",
    "    for i in range(timesteps,val.shape[0]):\n",
    "        X_val.append(val[i-timesteps:i])\n",
    "        Y_val.append(val[i][0])\n",
    "    X_val,Y_val = np.array(X_val),np.array(Y_val)\n",
    "    \n",
    "    # Adding Layers to the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(X_train.shape[2],input_shape = (X_train.shape[1],X_train.shape[2]),return_sequences = True,\n",
    "                   activation = 'relu'))\n",
    "    for i in range(len(hl)-1):        \n",
    "        model.add(LSTM(hl[i],activation = 'relu',return_sequences = True))\n",
    "    model.add(LSTM(hl[-1],activation = 'relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer = optimizers.Adam(lr = lr), loss = 'mean_squared_error')\n",
    "    #print(model.summary())\n",
    "  \n",
    "    # Training the data\n",
    "    history = model.fit(X_train,Y_train,epochs = epochs,batch_size = batch,validation_data = (X_val, Y_val),verbose = 0,\n",
    "                        shuffle = False)#, callbacks=callbacks_list)\n",
    "    model.reset_states()\n",
    "    return model, history.history['loss'], history.history['val_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LpwHmJeQJqyI"
   },
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "def evaluate_model(model,test,timesteps):\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "\n",
    "    # Loop for testing data\n",
    "    for i in range(timesteps,test.shape[0]):\n",
    "        X_test.append(test[i-timesteps:i])\n",
    "        Y_test.append(test[i][0])\n",
    "    X_test,Y_test = np.array(X_test),np.array(Y_test)\n",
    "    \n",
    "    # Prediction Time !!!!\n",
    "    Y_hat = model.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(Y_test,Y_hat))\n",
    "    r2 = r2_score(Y_test,Y_hat)\n",
    "    return rmse, r2, Y_test, Y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pI0q18ajCLx6"
   },
   "outputs": [],
   "source": [
    "# Plotting the predictions\n",
    "def plot_data(Y_test,Y_hat):\n",
    "    plt.plot(Y_test,c = 'r')\n",
    "    plt.plot(Y_hat,c = 'y')\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title('Stock Prediction Graph using Multivariate-LSTM model')\n",
    "    plt.legend(['Actual','Predicted'],loc = 'lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4NeqKRBZZr0Q"
   },
   "outputs": [],
   "source": [
    "# Plotting the training errors\n",
    "def plot_error(train_loss,val_loss):\n",
    "    plt.plot(train_loss,c = 'r')\n",
    "    plt.plot(val_loss,c = 'b')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['train','val'],loc = 'upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gAvOMIyjIQO-"
   },
   "outputs": [],
   "source": [
    "# Extracting the series\n",
    "series = df[['Close','High','Volume']] # Picking the series with high correlation\n",
    "print(series.shape)\n",
    "print(series.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tjso-RjNDmbs"
   },
   "outputs": [],
   "source": [
    "# Train Val Test Split\n",
    "train_start = dt.date(1997,1,1)\n",
    "train_end = dt.date(2006,12,31)\n",
    "train_data = series.loc[train_start:train_end]\n",
    "\n",
    "val_start = dt.date(2007,1,1)\n",
    "val_end = dt.date(2008,12,31)\n",
    "val_data = series.loc[val_start:val_end]\n",
    "\n",
    "test_start = dt.date(2009,1,1)\n",
    "test_end = dt.date(2010,12,31)\n",
    "test_data = series.loc[test_start:test_end]\n",
    "\n",
    "print(train_data.shape,val_data.shape,test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWXR5oL2ZnY4"
   },
   "outputs": [],
   "source": [
    "# Normalisation\n",
    "sc = MinMaxScaler()\n",
    "train = sc.fit_transform(train_data)\n",
    "val = sc.transform(val_data)\n",
    "test = sc.transform(test_data)\n",
    "print(train.shape,val.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list()\n",
    "for t in timesteps:\n",
    "    for l in hl:\n",
    "        for rate in lr:\n",
    "            for batch in batch_size:\n",
    "                for epochs in num_epochs:\n",
    "                    model,train_loss,val_loss = fit_model(train,val,t,l,rate,batch,epochs)\n",
    "                    results.append([t,l,rate,batch,train_loss[-1],val_loss[-1]])\n",
    "pd.DataFrame(results,columns=['Timestep','Hidden_Layers','Learning_Rate','Batch_Size','Train_Loss','Val_Loss']).to_csv('Multivariate-3-LSTM_model1.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "timesteps = 42\n",
    "hl = [35,30]\n",
    "lr = 1.5e-5\n",
    "batch_size = 32\n",
    "num_epochs = 500\n",
    "model,train_error,val_error = fit_model(train,val,timesteps,hl,lr,batch_size,num_epochs)\n",
    "plot_error(train_error,val_error)\n",
    "rmse, r2_value,true,predicted = evaluate_model(model,test,42)\n",
    "print('R-Squared Score = {}'.format(r2_value))\n",
    "plot_data(true,predicted)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mJnzFIPCZnw"
   },
   "outputs": [],
   "source": [
    "# Save a model\n",
    "#model.save('model1.h5')\n",
    "\n",
    "# Load a model\n",
    "#model = load_model('model1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2\n",
    "Converting volume to log scale and see what changes happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Converting Volume to log scale\n",
    "df['Volume_log'] = np.log(df['Volume'])\n",
    "print(df['Volume_log'].describe())\n",
    "df['Volume_log'].hist(bins=20)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gAvOMIyjIQO-"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Extracting the series\n",
    "series = df[['Close','High','Volume_log']] # Picking the multivariate series \n",
    "print(series.shape)\n",
    "print(series.tail())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tjso-RjNDmbs"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Train Val Test Split\n",
    "train_start = dt.date(1997,1,1)\n",
    "train_end = dt.date(2006,12,31)\n",
    "train_data = series.loc[train_start:train_end]\n",
    "\n",
    "val_start = dt.date(2007,1,1)\n",
    "val_end = dt.date(2008,12,31)\n",
    "val_data = series.loc[val_start:val_end]\n",
    "\n",
    "test_start = dt.date(2009,1,1)\n",
    "test_end = dt.date(2010,12,31)\n",
    "test_data = series.loc[test_start:test_end]\n",
    "\n",
    "print(train_data.shape,val_data.shape,test_data.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWXR5oL2ZnY4"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Normalisation\n",
    "sc = MinMaxScaler()\n",
    "train = sc.fit_transform(train_data)\n",
    "val = sc.transform(val_data)\n",
    "test = sc.transform(test_data)\n",
    "print(train.shape,val.shape,test.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "results = list()\n",
    "for l in hl:\n",
    "    for rate in lr:\n",
    "        for batch in batch_size:\n",
    "            for epochs in num_epochs:\n",
    "                model,train_loss,val_loss = fit_model(train,val,timesteps[1],l,rate,batch,epochs)\n",
    "                results.append([timesteps[1],l,rate,batch,train_loss[-1],val_loss[-1]])\n",
    "pd.DataFrame(results,columns=['Timestep','Hidden_Layers','Learning_Rate','Batch_Size','Train_Loss','Val_Loss']).to_csv('Multivariate-3-LSTM_1.csv')\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "timesteps = 40\n",
    "hl = [40,35]\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 500\n",
    "model,train_error,val_error = fit_model(train,val,timesteps,hl,lr,batch_size,num_epochs)\n",
    "plot_error(train_error,val_error)\n",
    "rmse, r2_value,true,predicted = evaluate_model(model,test,42)\n",
    "print('R-Squared Score = {}'.format(r2_value))\n",
    "plot_data(true,predicted)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mJnzFIPCZnw"
   },
   "outputs": [],
   "source": [
    "# Save a model\n",
    "#model.save('model_LSTM_30_4035_1e-3.h5')\n",
    "#del model # Deletes the model\n",
    "# Load a model\n",
    "#model = load_model('model2.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Multivariate_Stock_Analysis-3-LSTM.ipynb",
   "provenance": [
    {
     "file_id": "1TbS1iN6r9LWkUIIg2eyr5EB0pIzV5yAK",
     "timestamp": 1551228758851
    },
    {
     "file_id": "1iQNCZLjJhQ56R4aZ1sLrnNQ4PS2KfN2m",
     "timestamp": 1551146300148
    },
    {
     "file_id": "1OKnKPBI38XYPGQW0xUAj0nnJbfO6SuXE",
     "timestamp": 1550670800726
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
